{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Project Name and Explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas.plotting\n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from scipy import optimize\n",
    "\n",
    "# Statistical Models \n",
    "from pandas.plotting import radviz\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "from scipy.stats import sem\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "\n",
    "\n",
    "#from yellowbrick.regressor import PredictionError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model \n",
    "Note: Review previous notebooks ( \"Data Ingestion\" and \"Data Wrangling\") to execute the following code\n",
    "\n",
    "Dataframes were created in these notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"5-Merge.csv \" from Data Ingestion and Data Wrangling Notebooks\n",
    "\n",
    "dataset = pd.read_csv('5-MERGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reset index\n",
    "\n",
    "dataset_dtypes = pd.DataFrame(dataset.dtypes,columns=['dtypes'])\n",
    "dataset_dtypes = dataset_dtypes.reset_index()\n",
    "dataset_dtypes['name'] = dataset_dtypes['index']\n",
    "dataset_dtypes = dataset_dtypes[['name','dtypes']]\n",
    "dataset_dtypes['first value'] = dataset.loc[0].values #first row and column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kern      36\n",
      "Fresno    36\n",
      "Name: County, dtype: int64\n",
      "2015    2\n",
      "2014    2\n",
      "1995    2\n",
      "1994    2\n",
      "1993    2\n",
      "1992    2\n",
      "1991    2\n",
      "1990    2\n",
      "1989    2\n",
      "1988    2\n",
      "1987    2\n",
      "1986    2\n",
      "1985    2\n",
      "1984    2\n",
      "1983    2\n",
      "1982    2\n",
      "1981    2\n",
      "1996    2\n",
      "1997    2\n",
      "1998    2\n",
      "2007    2\n",
      "2013    2\n",
      "2012    2\n",
      "2011    2\n",
      "2010    2\n",
      "2009    2\n",
      "2008    2\n",
      "2006    2\n",
      "1999    2\n",
      "2005    2\n",
      "2004    2\n",
      "2003    2\n",
      "2002    2\n",
      "2001    2\n",
      "2000    2\n",
      "1980    2\n",
      "Name: Year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verfying appropiate counties and year\n",
    "\n",
    "print(dataset.County.value_counts())\n",
    "print(dataset.Year.value_counts())\n",
    "\n",
    "#print(dataset.County_Code.value_counts())\n",
    "#print(dataset.Commodity_Code.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                           int64\n",
      "Commodity_Code                 int64\n",
      "County_Code                    int64\n",
      "County                        object\n",
      "Harvested                      int64\n",
      "Yield                        float64\n",
      "Production                     int64\n",
      "Price                        float64\n",
      "Value                          int64\n",
      "January_p                    float64\n",
      "February_p                   float64\n",
      "March_p                      float64\n",
      "April_p                      float64\n",
      "May_p                        float64\n",
      "June_p                       float64\n",
      "July_p                       float64\n",
      "August_p                     float64\n",
      "September_p                  float64\n",
      "October_p                    float64\n",
      "November_p                   float64\n",
      "December_p                   float64\n",
      "Total_p                      float64\n",
      "January_t                    float64\n",
      "February_t                   float64\n",
      "March_t                      float64\n",
      "April_t                      float64\n",
      "May_t                        float64\n",
      "June_t                       float64\n",
      "July_t                       float64\n",
      "August_t                     float64\n",
      "September_t                  float64\n",
      "October_t                    float64\n",
      "November_t                   float64\n",
      "December_t                   float64\n",
      "Annual_t                     float64\n",
      "Percapita_Personal_Income    float64\n",
      "Personal_Income              float64\n",
      "Resident_Population          float64\n",
      "House_Price_Index            float64\n",
      "dtype: object\n",
      "Index(['Year', 'Commodity_Code', 'County_Code', 'County', 'Harvested', 'Yield',\n",
      "       'Production', 'Price', 'Value', 'January_p', 'February_p', 'March_p',\n",
      "       'April_p', 'May_p', 'June_p', 'July_p', 'August_p', 'September_p',\n",
      "       'October_p', 'November_p', 'December_p', 'Total_p', 'January_t',\n",
      "       'February_t', 'March_t', 'April_t', 'May_t', 'June_t', 'July_t',\n",
      "       'August_t', 'September_t', 'October_t', 'November_t', 'December_t',\n",
      "       'Annual_t', 'Percapita_Personal_Income', 'Personal_Income',\n",
      "       'Resident_Population', 'House_Price_Index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Check column data types and names\n",
    "\n",
    "print(dataset.dtypes)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dataset.shape) # Number of rows and columns \n",
    "#print(dataset.describe()) #Data information \n",
    "#print(dataset.head()) \n",
    "#print(dataset.Production.mean()) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define feature and target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Indicators for Prediction \n",
    "\n",
    "features = ['Year','Production','Harvested','Price','Value','Annual_t','Total_p']\n",
    "#features = ['Year', 'Harvested', 'Yield','Price','']\n",
    "\n",
    "#What we want to Predict \n",
    "target = 'Yield' \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# l1 and L2 Regularization \n",
    "alphas = np.logspace(-10, 0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines indicators and prediction value(s)\n",
    "X = (dataset[features])\n",
    "y = (dataset[target])\n",
    "\n",
    "#X=preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create training and test splits \n",
    "\n",
    "# 20% of the data is used for testing (meaning of test_size = 0.2)\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Regression Models \n",
    "1. Linear regression \n",
    "2. ElasticNet \n",
    "3. Lasso CV\n",
    "4. Pipeline \n",
    "5. Random Forest \n",
    "6. AdaBoost\n",
    "7. Bayesian Ridge \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression \n",
    "\n",
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.862 MSE=0.004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nor\\naccuracy=model.score(X_test,y_test)\\nprint('Accuracy',accuracy)\\n\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "\"\"\"\n",
    "or\n",
    "accuracy=model.score(X_test,y_test)\n",
    "print('Accuracy',accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.859 MSE=0.004\n"
     ]
    }
   ],
   "source": [
    "# EllasticNet\n",
    "\n",
    "# takes model and fits to training data (20%)\n",
    "model = ElasticNetCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Y target (prediction) based on the above\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# R2 coefficient \n",
    "r2 = r2_score(y_test, yhat)\n",
    "\n",
    "#Mean Square Error \n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me)) # .3f formates decimal places "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.858 MSE=0.004 alpha=0.011\n"
     ]
    }
   ],
   "source": [
    "#LassoCV\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "model = LassoCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f2fe5381da77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model = Pipeline([\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'poly'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'lasso'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('lasso', LassoCV(alphas=alphas)),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['lasso'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-510df66537d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.246 MSE=0.021\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = AdaBoostRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.848 MSE=0.004\n"
     ]
    }
   ],
   "source": [
    "#Bayesian Ridge\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "model = BayesianRidge() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test) #predicted\n",
    "\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b303f44d48a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPredictionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Instantiate the visualizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "# Yellowbrick \n",
    "# Can use the above models for the code blow. Just replace the model name\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "#Instantiate the visualizer \n",
    "visualizer = PredictionError(Lasso())\n",
    "\n",
    "#Fit\n",
    "visualizer.fit(X_train, y_learn)\n",
    "\n",
    "#Score and Visualize\n",
    "visualizer.score(x_test, y_test)\n",
    "visualizer.proof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1e24ab506e59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPredictionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Instantiate the visualizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredictionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBayesianRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "\n",
    "from yellowbrick.regressor import PredictionError\n",
    "\n",
    "#Instantiate the visualizer \n",
    "visualizer = PredictionError(BayesianRidge())\n",
    "\n",
    "#Fit\n",
    "visualizer.fit(X_train, y_learn)\n",
    "\n",
    "#Score and Visualize\n",
    "visualizer.score(x_test, y_test)\n",
    "visualizer.proof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
